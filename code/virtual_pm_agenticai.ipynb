{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwdQhTEb6VAu"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langgraph\n",
        "!pip install pandas\n",
        "!pip install langchain_experimental\n",
        "!pip install ibm_watson_machine_learning\n",
        "!pip install langchain-ibm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "atNixbetBdYg"
      },
      "outputs": [],
      "source": [
        "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
        "from langchain_ibm import WatsonxEmbeddings, WatsonxLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVi4hwL8BTgf"
      },
      "outputs": [],
      "source": [
        "llm= WatsonxLLM(\n",
        "    model_id=\"ibm/granite-3-8b-instruct\",\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    apikey=\"xxxxxxxxxxxxxx__4XBZxxxxxxxxxxxxxL\",\n",
        "    project_id=\"xxxxxxxxxxxxxxxxx_bb1b-exxxxxxxxxxxxx\",\n",
        "    params={\n",
        "      GenParams.DECODING_METHOD: \"greedy\",\n",
        "      GenParams.TEMPERATURE: 0.7,\n",
        "      GenParams.MIN_NEW_TOKENS: 5,\n",
        "      GenParams.MAX_NEW_TOKENS:1000,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG_E4pRq7Qt4",
        "outputId": "4d2ef31d-2512-44c3-9a55-51de67d221ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "BUSINESS ANALYTICS REPORTING SYSTEM\n",
            "============================================================\n",
            "\n",
            "QUERY: Total revenue generated for PROD001 and PROD002\n",
            "------------------------------------------------------------\n",
            "### 1. KEY FINDINGS:\n",
            "\n",
            "- **Total Revenue Generated:**\n",
            "  - **PROD001:** $25,384.32\n",
            "  - **PROD002:** $18,604.30\n",
            "  - **Combined Total Revenue:** $43,988.62\n",
            "\n",
            "- **Comparison:**\n",
            "  - PROD001 generated 36.55% more revenue than PROD002.\n",
            "\n",
            "### 2. KEY INSIGHTS:\n",
            "\n",
            "- **Revenue Distribution:**\n",
            "  - PROD001 contributes significantly more to the total revenue compared to PROD002. This indicates a higher market demand or better market penetration for PROD001.\n",
            "\n",
            "- **Market Performance:**\n",
            "  - The difference in revenue between the two products suggests varying levels of consumer preference or possibly different pricing strategies. PROD001’s higher revenue could be indicative of higher pricing, greater volume sold, or a combination of both.\n",
            "\n",
            "- **Potential Market Trends:**\n",
            "  - The substantial revenue from PROD001 might reflect a trend where customers prefer its features, quality, or value proposition over that of PROD002.\n",
            "\n",
            "### 3. RECOMMENDATIONS:\n",
            "\n",
            "1. **Enhance Marketing Efforts for PROD002:**\n",
            "   - **Rationale:** To balance the revenue generation between products and increase market share.\n",
            "   - **Implementation:** Conduct market research to understand the lower performance and tailor marketing strategies accordingly (e.g., targeted promotions, advertising campaigns).\n",
            "\n",
            "2. **Review Pricing Strategy for PROD001 and PROD002:**\n",
            "   - **Rationale:** To maximize revenue while maintaining competitive pricing.\n",
            "   - **Implementation:** Analyze competitor pricing and customer sensitivity to adjust prices without sacrificing sales volume.\n",
            "\n",
            "3. **Product Development Focus on PROD001:**\n",
            "   - **Rationale:** Leverage the existing popularity and higher revenue generation of PROD001.\n",
            "   - **Implementation:** Invest in R&D to further enhance the product features and introduce new variants to capture a larger customer base.\n",
            "\n",
            "4. **Cross-Promotional Strategies:**\n",
            "   - **Rationale:** Utilize the popularity of PROD001 to boost sales for PROD002.\n",
            "   - **Implementation:** Bundle both products at a discounted rate, or offer PROD002 as an upsell to purchases of PROD001.\n",
            "\n",
            "### 4. CONCLUSION:\n",
            "\n",
            "- **Summary of Key Takeaways:**\n",
            "  - PROD001 is a stronger revenue generator compared to PROD002, indicating a potential preference or better market fit.\n",
            "  - There is an opportunity to improve the performance of PROD002 through targeted marketing and possibly revising its pricing strategy.\n",
            "\n",
            "- **Next Steps for the Business:**\n",
            "  - Implement the recommended strategies focusing on marketing, pricing adjustments, and product development to optimize revenue streams from both products.\n",
            "\n",
            "- **Final Thoughts:**\n",
            "  - Continuous monitoring of sales performance post-implementation of these strategies will be crucial to adapt and ensure both products contribute optimally to the business’s bottom line.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from typing import TypedDict, List, Dict, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "import asyncio\n",
        "\n",
        "# Load and preprocess datasets\n",
        "def load_datasets():\n",
        "    datasets = {\n",
        "        'ratings': pd.read_csv('Ratings&Sentiments_POC - Sheet1.csv'),\n",
        "        'complaints': pd.read_csv('Complaints_POC - Sheet1.csv'),\n",
        "        'sales': pd.read_csv('Sales_POC - Sheet1.csv'),\n",
        "        'marketing': pd.read_csv('Marketing_POC - Sheet1.csv'),\n",
        "        'teamperformance': pd.read_csv('TeamPerformance_POC - Sheet1.csv')\n",
        "    }\n",
        "\n",
        "    # Standardize column names and types\n",
        "    for name, df in datasets.items():\n",
        "        df.columns = df.columns.str.strip().str.lower().str.replace('[^a-z0-9_]', '_', regex=True)\n",
        "\n",
        "        # Convert date columns\n",
        "        for col in df.columns:\n",
        "            if 'date' in col:\n",
        "                df[col] = pd.to_datetime(df[col])\n",
        "\n",
        "        # Convert numeric columns\n",
        "        for col in df.select_dtypes(include=['object']).columns:\n",
        "            try:\n",
        "                df[col] = pd.to_numeric(df[col])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Standardize string values\n",
        "        for col in df.select_dtypes(include=['object']).columns:\n",
        "            df[col] = df[col].astype(str).str.strip().str.upper()\n",
        "\n",
        "    return datasets\n",
        "\n",
        "datasets = load_datasets()\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    query: str\n",
        "    interpretation: dict\n",
        "    department_results: dict\n",
        "    final_response: str\n",
        "    error: Optional[str]\n",
        "\n",
        "llm = llm\n",
        "\n",
        "async def interpret_query(state: GraphState):\n",
        "    \"\"\"Convert natural language queries into structured data requests\"\"\"\n",
        "    system_msg = \"\"\"You are an expert query interpreter. Convert the user's query into JSON format specifying:\n",
        "\n",
        "1. departments: Which datasets to query (ratings, complaints, sales, marketing, teamperformance)\n",
        "2. products: List of product IDs (PROD001-PROD007) if specified\n",
        "3. metrics: Specific columns to retrieve\n",
        "4. aggregation: How to process the data (sum, avg, count, list)\n",
        "\n",
        "Example outputs:\n",
        "1. \"Total revenue for PROD001\":\n",
        "{\n",
        "  \"departments\": [\"sales\"],\n",
        "  \"products\": [\"PROD001\"],\n",
        "  \"metrics\": [\"net_revenue\"],\n",
        "  \"aggregation\": \"sum\"\n",
        "}\n",
        "\n",
        "2. \"Complaints about PROD006\":\n",
        "{\n",
        "  \"departments\": [\"complaints\"],\n",
        "  \"products\": [\"PROD006\"],\n",
        "  \"metrics\": [\"issue_description\"],\n",
        "  \"aggregation\": \"list\"\n",
        "}\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = await llm.ainvoke([\n",
        "            SystemMessage(content=system_msg),\n",
        "            HumanMessage(content=state[\"query\"])\n",
        "        ])\n",
        "        interpretation = json.loads(response.content)\n",
        "\n",
        "        # Validate the interpretation\n",
        "        required_keys = ['departments', 'products', 'metrics', 'aggregation']\n",
        "        if not all(k in interpretation for k in required_keys):\n",
        "            raise ValueError(\"Missing required fields in interpretation\")\n",
        "\n",
        "        return {\"interpretation\": interpretation, \"error\": None}\n",
        "    except Exception as e:\n",
        "        return {\"interpretation\": {}, \"error\": f\"Interpretation failed: {str(e)}\"}\n",
        "\n",
        "async def process_departments(state: GraphState):\n",
        "    \"\"\"Execute data processing based on the interpretation\"\"\"\n",
        "    if not state.get(\"interpretation\"):\n",
        "        return {\"department_results\": {}, \"error\": \"No interpretation provided\"}\n",
        "\n",
        "    results = {}\n",
        "    interpretation = state[\"interpretation\"]\n",
        "\n",
        "    for dept in interpretation[\"departments\"]:\n",
        "        if dept not in datasets:\n",
        "            continue\n",
        "\n",
        "        df = datasets[dept]\n",
        "        dept_results = {}\n",
        "\n",
        "        # Handle product filtering\n",
        "        products = interpretation[\"products\"] or (\n",
        "            df['product_id'].unique().tolist() if 'product_id' in df.columns else ['ALL']\n",
        "        )\n",
        "\n",
        "        for product in products:\n",
        "            if 'product_id' in df.columns:\n",
        "                product_data = df[df['product_id'].str.upper() == product.upper()]\n",
        "            else:\n",
        "                product_data = df\n",
        "\n",
        "            if product_data.empty:\n",
        "                continue\n",
        "\n",
        "            metric_results = {}\n",
        "            for metric in interpretation[\"metrics\"]:\n",
        "                if metric not in product_data.columns:\n",
        "                    continue\n",
        "\n",
        "                # Apply the requested aggregation\n",
        "                agg_func = interpretation[\"aggregation\"]\n",
        "                if agg_func == \"sum\":\n",
        "                    value = product_data[metric].sum()\n",
        "                elif agg_func in [\"avg\", \"mean\"]:\n",
        "                    value = round(product_data[metric].mean(), 2)\n",
        "                elif agg_func == \"count\":\n",
        "                    value = product_data[metric].count()\n",
        "                elif agg_func == \"list\":\n",
        "                    value = product_data[metric].tolist()\n",
        "                else:  # Default to first value\n",
        "                    value = product_data[metric].iloc[0]\n",
        "\n",
        "                metric_results[metric] = value\n",
        "\n",
        "            if metric_results:\n",
        "                dept_results[product] = metric_results\n",
        "\n",
        "        if dept_results:\n",
        "            results[dept] = dept_results\n",
        "\n",
        "    return {\"department_results\": results, \"error\": None}\n",
        "\n",
        "async def generate_response(state: GraphState):\n",
        "    \"\"\"Generate comprehensive business report with insights and recommendations\"\"\"\n",
        "    if not state.get(\"department_results\"):\n",
        "        return await fallback_response(state[\"query\"])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a senior business analyst. Create a detailed report with these sections:\n",
        "\n",
        "1. KEY FINDINGS:\n",
        "   - Present all requested metrics clearly with proper formatting\n",
        "   - Include comparisons where relevant\n",
        "   - Highlight key statistics\n",
        "\n",
        "2. KEY INSIGHTS:\n",
        "   - Analyze what the numbers mean in business context\n",
        "   - Identify patterns, trends, and anomalies\n",
        "   - Explain potential causes for observed results\n",
        "\n",
        "3. RECOMMENDATIONS:\n",
        "   - Provide 3-5 actionable business recommendations\n",
        "   - Prioritize by potential impact\n",
        "   - Include implementation considerations\n",
        "\n",
        "4. CONCLUSION:\n",
        "   - Summary of key takeaways\n",
        "   - Next steps for the business\n",
        "   - Final thoughts\n",
        "\n",
        "Data: {data}\n",
        "\n",
        "Current Date: {current_date}\"\"\"),\n",
        "        (\"human\", \"Original Query: {query}\")\n",
        "    ])\n",
        "\n",
        "    try:\n",
        "        response = await (prompt | llm).ainvoke({\n",
        "            \"query\": state[\"query\"],\n",
        "            \"data\": json.dumps(state[\"department_results\"], indent=2),\n",
        "            \"current_date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "        })\n",
        "        return {\"final_response\": response.content, \"error\": None}\n",
        "    except Exception as e:\n",
        "        return await fallback_response(state[\"query\"])\n",
        "\n",
        "async def fallback_response(query: str):\n",
        "    \"\"\"Direct data lookup with insights when interpretation fails\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Try to extract product IDs\n",
        "    products = re.findall(r'PROD\\d{3}', query.upper()) or ['ALL']\n",
        "\n",
        "    # Check all datasets for relevant data\n",
        "    for name, df in datasets.items():\n",
        "        dept_results = {}\n",
        "\n",
        "        for product in products:\n",
        "            if 'product_id' in df.columns:\n",
        "                product_data = df[df['product_id'].str.upper() == product.upper()]\n",
        "            else:\n",
        "                product_data = df\n",
        "\n",
        "            if product_data.empty:\n",
        "                continue\n",
        "\n",
        "            # Auto-detect metrics based on query\n",
        "            if 'rating' in query.lower() and 'rating' in df.columns:\n",
        "                dept_results[product] = {\n",
        "                    'average_rating': round(product_data['rating'].mean(), 2),\n",
        "                    'rating_distribution': product_data['rating'].value_counts().to_dict()\n",
        "                }\n",
        "            elif 'unit' in query.lower() and 'units_sold' in df.columns:\n",
        "                dept_results[product] = {\n",
        "                    'total_units_sold': int(product_data['units_sold'].sum())\n",
        "                }\n",
        "            elif 'revenue' in query.lower() and 'net_revenue' in df.columns:\n",
        "                dept_results[product] = {\n",
        "                    'total_revenue': product_data['net_revenue'].sum()\n",
        "                }\n",
        "            elif 'complaint' in query.lower() and 'issue_description' in df.columns:\n",
        "                dept_results[product] = {\n",
        "                    'complaints': product_data['issue_description'].tolist(),\n",
        "                    'recurring_issues': product_data[product_data['recurring_flag'] == 'YES']['issue_description'].tolist()\n",
        "                }\n",
        "\n",
        "        if dept_results:\n",
        "            results[name] = dept_results\n",
        "\n",
        "    if results:\n",
        "        # Generate comprehensive insights from the direct data\n",
        "        insight_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"Generate a detailed business report with:\n",
        "\n",
        "1. KEY FINDINGS: Present the data clearly\n",
        "2. INSIGHTS: Analyze patterns and business implications\n",
        "3. RECOMMENDATIONS: 3-5 actionable suggestions\n",
        "4. CONCLUSION: Summary and next steps\n",
        "\n",
        "Data: {data}\"\"\"),\n",
        "            (\"human\", \"Query: {query}\")\n",
        "        ])\n",
        "\n",
        "        insight_response = await (insight_prompt | llm).ainvoke({\n",
        "            \"query\": query,\n",
        "            \"data\": json.dumps(results, indent=2)\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            \"final_response\": insight_response.content,\n",
        "            \"error\": None\n",
        "        }\n",
        "\n",
        "    return {\"final_response\": \"No relevant data found. Please try rephrasing your query.\", \"error\": None}\n",
        "\n",
        "# Build the workflow graph\n",
        "workflow = StateGraph(GraphState)\n",
        "workflow.add_node(\"interpret\", interpret_query)\n",
        "workflow.add_node(\"process\", process_departments)\n",
        "workflow.add_node(\"respond\", generate_response)\n",
        "workflow.add_edge(\"interpret\", \"process\")\n",
        "workflow.add_edge(\"process\", \"respond\")\n",
        "workflow.add_edge(\"respond\", END)\n",
        "workflow.set_entry_point(\"interpret\")\n",
        "app = workflow.compile()\n",
        "\n",
        "async def execute_query(query: str):\n",
        "    \"\"\"Run the full analysis pipeline\"\"\"\n",
        "    result = await app.ainvoke({\"query\": query})\n",
        "    return result.get(\"final_response\", \"No response generated\")\n",
        "\n",
        "# Example test cases\n",
        "test_queries = [\n",
        "    \"Total revenue generated for PROD001 and PROD002\"\n",
        "]\n",
        "\n",
        "async def run_demo():\n",
        "    print(\"=\"*60)\n",
        "    print(\"BUSINESS ANALYTICS REPORTING SYSTEM\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\nQUERY: {query}\")\n",
        "        print(\"-\"*60)\n",
        "        response = await execute_query(query)\n",
        "        print(response)\n",
        "        print(\"-\"*60)\n",
        "\n",
        "# Proper async context handling\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        asyncio.run(run_demo())\n",
        "    except RuntimeError as e:\n",
        "        if \"running event loop\" in str(e):\n",
        "            loop = asyncio.get_event_loop()\n",
        "            loop.run_until_complete(run_demo())\n",
        "        else:\n",
        "            raise"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
